





树模型
1.不做缺失值，不做one-hot，直接输入GBDT(LightGBM）
	对分类数据做one-hot
2.DT
	sklearn dt
		string可以用hash，也可以做one hot
			pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)[source]
			原因——sklearn dt算法默认是连续数值型输入，1.hash会导致出现数值有序增加噪声，
												   2.sklearn只能转换成one-hot，因为不能处理categorical/string variables.

3.不做特征工程和处理，RF

树模型可以采用integer-encoding对category var做预处理
	因为决策树模型的Gain分类标准是用熵的增减，不用到欧氏距离

	


分类	
 分类数据one-hot处理
3.SVM
4.LR
数据缺失：
	分类，如果是LR\SVM，对于高维稀疏数据可以缺失值直接做one-hot
	数值，


ks, auc, psi
分类变量之间的距离 汉明距离 hamming distance


缺失值
	缺失之间的相关，直接把缺失全部标成1，非缺失全部标成0。两个二分类之间做卡方检验
		如果卡方没过，在大样本情况下怎么做进一步的检验？
		这只能检验一个的相关，如果依赖于多个变量的怎么做？
	0-1
		聚类填充
		knn
			注意做正则化，基于距离
			不适合高维数据
			time consuming 全数据集搜索 kd树
			originally 用于连续数据
			对于混合数据集，？

	10-20
		分类的做one-hot处理
		连续

多重插补（Multiple Impution)
	（原理，后补？）
	做多次，然后丢模型取平均之类的思路——不采用

EM




1.LightGBM啥都不做版
2.LR\SVM数据预处理+无脑训练版
